{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef0f975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://g01.itversity.com:37925\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fcb6d4f3898>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import getpass\n",
    "\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession.\\\n",
    "builder. \\\n",
    "config('spark.ui.port','0'). \\\n",
    "config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "enableHiveSupport(). \\\n",
    "master('yarn'). \\\n",
    "getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2242a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = spark.read.format(\"csv\")\\\n",
    ".option(\"header\",\"true\")\\\n",
    ".option(\"inferSchema\",\"true\")\\\n",
    ".load(\"/public/trendytech/orders_wh/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbf7cc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+-----------+---------------+\n",
      "|order_id|order_date           |customer_id|order_status   |\n",
      "+--------+---------------------+-----------+---------------+\n",
      "|1       |2013-07-25 00:00:00.0|11599      |CLOSED         |\n",
      "|2       |2013-07-25 00:00:00.0|256        |PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00.0|12111      |COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00.0|8827       |CLOSED         |\n",
      "|5       |2013-07-25 00:00:00.0|11318      |COMPLETE       |\n",
      "|6       |2013-07-25 00:00:00.0|7130       |COMPLETE       |\n",
      "|7       |2013-07-25 00:00:00.0|4530       |COMPLETE       |\n",
      "|8       |2013-07-25 00:00:00.0|2911       |PROCESSING     |\n",
      "|9       |2013-07-25 00:00:00.0|5657       |PENDING_PAYMENT|\n",
      "|10      |2013-07-25 00:00:00.0|5648       |PENDING_PAYMENT|\n",
      "|11      |2013-07-25 00:00:00.0|918        |PAYMENT_REVIEW |\n",
      "|12      |2013-07-25 00:00:00.0|1837       |CLOSED         |\n",
      "|13      |2013-07-25 00:00:00.0|9149       |PENDING_PAYMENT|\n",
      "|14      |2013-07-25 00:00:00.0|9842       |PROCESSING     |\n",
      "|15      |2013-07-25 00:00:00.0|2568       |COMPLETE       |\n",
      "|16      |2013-07-25 00:00:00.0|7276       |PENDING_PAYMENT|\n",
      "|17      |2013-07-25 00:00:00.0|2667       |COMPLETE       |\n",
      "|18      |2013-07-25 00:00:00.0|1205       |CLOSED         |\n",
      "|19      |2013-07-25 00:00:00.0|9488       |PENDING_PAYMENT|\n",
      "|20      |2013-07-25 00:00:00.0|9198       |PROCESSING     |\n",
      "+--------+---------------------+-----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.show(truncate=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4a5a77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d36f05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df1 = orders_df.withColumnRenamed(\"order_status\",\"status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1b8c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "transformed_df2 = transformed_df1.withColumn(\"order_date_new\",to_timestamp(\"order_date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e523e5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- order_date_new: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed_df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "940c9d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df = transformed_df2.select(\"order_id\",\"customer_id\",\"status\",\"order_date_new\")\\\n",
    ".withColumnRenamed(\"order_date_new\",\"order_date \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f04980be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- order_date : timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fin_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce5ec92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a0d2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897b217f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9619270",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df=spark.read.\\\n",
    "format(\"csv\").\\\n",
    "option(\"header\",\"true\").\\\n",
    "option(\"inferSchema\",\"true\").\\\n",
    "load(\"/public/trendytech/orders_wh/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e945894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+---------------+\n",
      "|order_id|          order_date|customer_id|   order_status|\n",
      "+--------+--------------------+-----------+---------------+\n",
      "|       1|2013-07-25 00:00:...|      11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:...|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:...|      12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:...|       8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:...|      11318|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:...|       7130|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:...|       4530|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:...|       2911|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:...|       5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:...|       5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:...|        918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:...|       1837|         CLOSED|\n",
      "|      13|2013-07-25 00:00:...|       9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:...|       9842|     PROCESSING|\n",
      "|      15|2013-07-25 00:00:...|       2568|       COMPLETE|\n",
      "|      16|2013-07-25 00:00:...|       7276|PENDING_PAYMENT|\n",
      "|      17|2013-07-25 00:00:...|       2667|       COMPLETE|\n",
      "|      18|2013-07-25 00:00:...|       1205|         CLOSED|\n",
      "|      19|2013-07-25 00:00:...|       9488|PENDING_PAYMENT|\n",
      "|      20|2013-07-25 00:00:...|       9198|     PROCESSING|\n",
      "+--------+--------------------+-----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "947c157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df2=spark.read\\\n",
    ".csv(\"/public/trendytech/orders_wh/*\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0125a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+---------------+\n",
      "|order_id|          order_date|customer_id|   order_status|\n",
      "+--------+--------------------+-----------+---------------+\n",
      "|       1|2013-07-25 00:00:...|      11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:...|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:...|      12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:...|       8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:...|      11318|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:...|       7130|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:...|       4530|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:...|       2911|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:...|       5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:...|       5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:...|        918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:...|       1837|         CLOSED|\n",
      "|      13|2013-07-25 00:00:...|       9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:...|       9842|     PROCESSING|\n",
      "|      15|2013-07-25 00:00:...|       2568|       COMPLETE|\n",
      "|      16|2013-07-25 00:00:...|       7276|PENDING_PAYMENT|\n",
      "|      17|2013-07-25 00:00:...|       2667|       COMPLETE|\n",
      "|      18|2013-07-25 00:00:...|       1205|         CLOSED|\n",
      "|      19|2013-07-25 00:00:...|       9488|PENDING_PAYMENT|\n",
      "|      20|2013-07-25 00:00:...|       9198|     PROCESSING|\n",
      "+--------+--------------------+-----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cf690d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: long (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df_json=spark.read\\\n",
    ".json(\"/public/trendytech/datasets/orders.json\")\n",
    "orders_df_json.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22f46f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: long (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df_parquet = spark.read\\\n",
    ".parquet(\"/public/trendytech/datasets/ordersparquet/\")\n",
    "orders_df_parquet.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20a32e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+--------+---------------+\n",
      "|customer_id|          order_date|order_id|   order_status|\n",
      "+-----------+--------------------+--------+---------------+\n",
      "|      11599|2013-07-25 00:00:...|       1|         CLOSED|\n",
      "|        256|2013-07-25 00:00:...|       2|PENDING_PAYMENT|\n",
      "|      12111|2013-07-25 00:00:...|       3|       COMPLETE|\n",
      "|       8827|2013-07-25 00:00:...|       4|         CLOSED|\n",
      "|      11318|2013-07-25 00:00:...|       5|       COMPLETE|\n",
      "|       7130|2013-07-25 00:00:...|       6|       COMPLETE|\n",
      "|       4530|2013-07-25 00:00:...|       7|       COMPLETE|\n",
      "|       2911|2013-07-25 00:00:...|       8|     PROCESSING|\n",
      "|       5657|2013-07-25 00:00:...|       9|PENDING_PAYMENT|\n",
      "|       5648|2013-07-25 00:00:...|      10|PENDING_PAYMENT|\n",
      "|        918|2013-07-25 00:00:...|      11| PAYMENT_REVIEW|\n",
      "|       1837|2013-07-25 00:00:...|      12|         CLOSED|\n",
      "|       9149|2013-07-25 00:00:...|      13|PENDING_PAYMENT|\n",
      "|       9842|2013-07-25 00:00:...|      14|     PROCESSING|\n",
      "|       2568|2013-07-25 00:00:...|      15|       COMPLETE|\n",
      "|       7276|2013-07-25 00:00:...|      16|PENDING_PAYMENT|\n",
      "|       2667|2013-07-25 00:00:...|      17|       COMPLETE|\n",
      "|       1205|2013-07-25 00:00:...|      18|         CLOSED|\n",
      "|       9488|2013-07-25 00:00:...|      19|PENDING_PAYMENT|\n",
      "|       9198|2013-07-25 00:00:...|      20|     PROCESSING|\n",
      "+-----------+--------------------+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df_orc = spark.read\\\n",
    ".orc(\"/public/trendytech/datasets/ordersorc/\")\n",
    "orders_df_orc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73809300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------+--------+------------+\n",
      "|customer_id|order_date           |order_id|order_status|\n",
      "+-----------+---------------------+--------+------------+\n",
      "|11599      |2013-07-25 00:00:00.0|1       |CLOSED      |\n",
      "|11599      |2013-10-03 00:00:00.0|11397   |COMPLETE    |\n",
      "|11599      |2013-12-20 00:00:00.0|23908   |COMPLETE    |\n",
      "|11599      |2014-06-27 00:00:00.0|53545   |PENDING     |\n",
      "|11599      |2013-10-17 00:00:00.0|59911   |PROCESSING  |\n",
      "+-----------+---------------------+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df=orders_df_orc.where(\"customer_id=11599\")\n",
    "#or\n",
    "#orders_df_orc.filter(\"customer_id=11599\")\n",
    "filtered_df.show(truncate=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e84914d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df_orc.createOrReplaceTempView(\"orders\") #df to a table/view conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77fd2fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------+--------+------------+\n",
      "|customer_id|order_date           |order_id|order_status|\n",
      "+-----------+---------------------+--------+------------+\n",
      "|11599      |2013-07-25 00:00:00.0|1       |CLOSED      |\n",
      "|8827       |2013-07-25 00:00:00.0|4       |CLOSED      |\n",
      "|1837       |2013-07-25 00:00:00.0|12      |CLOSED      |\n",
      "|1205       |2013-07-25 00:00:00.0|18      |CLOSED      |\n",
      "|11441      |2013-07-25 00:00:00.0|24      |CLOSED      |\n",
      "|9503       |2013-07-25 00:00:00.0|25      |CLOSED      |\n",
      "|5863       |2013-07-25 00:00:00.0|37      |CLOSED      |\n",
      "|12271      |2013-07-25 00:00:00.0|51      |CLOSED      |\n",
      "|7073       |2013-07-25 00:00:00.0|57      |CLOSED      |\n",
      "|4791       |2013-07-25 00:00:00.0|61      |CLOSED      |\n",
      "|9111       |2013-07-25 00:00:00.0|62      |CLOSED      |\n",
      "|3065       |2013-07-25 00:00:00.0|87      |CLOSED      |\n",
      "|9131       |2013-07-25 00:00:00.0|90      |CLOSED      |\n",
      "|5116       |2013-07-25 00:00:00.0|101     |CLOSED      |\n",
      "|8763       |2013-07-26 00:00:00.0|116     |CLOSED      |\n",
      "|9937       |2013-07-26 00:00:00.0|129     |CLOSED      |\n",
      "|10604      |2013-07-26 00:00:00.0|133     |CLOSED      |\n",
      "|16         |2013-07-26 00:00:00.0|191     |CLOSED      |\n",
      "|9055       |2013-07-26 00:00:00.0|201     |CLOSED      |\n",
      "|10372      |2013-07-26 00:00:00.0|211     |CLOSED      |\n",
      "+-----------+---------------------+--------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df=spark.sql(\"\"\"select * from orders where order_status='CLOSED'\"\"\")\n",
    "filtered_df.show(truncate=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d81f1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: long (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from spark table to df\n",
    "\n",
    "spark_tb_df = spark.read.table(\"orders\")\n",
    "spark_tb_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d0d191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a02aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ba301e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5008feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"create database if not exists 009490_retail\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed4b9dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|    namespace|\n",
      "+-------------+\n",
      "|009490_retail|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases \").filter(\"namespace like '009490%'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60ad3d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"use 009490_retail \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "393bc00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "|        |   orders|       true|\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70512045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE table if not exists 009490_retail.orders (order_id INT, order_date STRING, customer_id INT, order_status STRING)\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0be7c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----------+\n",
      "|     database| tableName|isTemporary|\n",
      "+-------------+----------+-----------+\n",
      "|009490_retail|orders_ext|      false|\n",
      "|             |    orders|       true|\n",
      "+-------------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85c1870e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"insert into 009490_retail.orders select * from orders\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbc455a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+---------------+\n",
      "|order_id|          order_date|customer_id|   order_status|\n",
      "+--------+--------------------+-----------+---------------+\n",
      "|    8702|2014-02-23 00:00:...|      34565|       COMPLETE|\n",
      "|    3066|2014-02-23 00:00:...|      34566|PENDING_PAYMENT|\n",
      "|    7314|2014-02-23 00:00:...|      34567|SUSPECTED_FRAUD|\n",
      "|    1271|2014-02-23 00:00:...|      34568|       COMPLETE|\n",
      "|   11083|2014-02-23 00:00:...|      34569|       COMPLETE|\n",
      "+--------+--------------------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"select * from 009490_retail.orders limit 5\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35ca8a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|createtab_stmt                                                                                                                                                                                      |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|CREATE TABLE `009490_retail`.`orders` (\n",
      "  `order_id` INT,\n",
      "  `order_date` STRING,\n",
      "  `customer_id` INT,\n",
      "  `order_status` STRING)\n",
      "USING text\n",
      "TBLPROPERTIES (\n",
      "  'transient_lastDdlTime' = '1698521421')\n",
      "|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show create table 009490_retail.orders\").show(truncate=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcc21288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+------------------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                                     |comment|\n",
      "+----------------------------+------------------------------------------------------------------------------+-------+\n",
      "|order_id                    |int                                                                           |null   |\n",
      "|order_date                  |string                                                                        |null   |\n",
      "|customer_id                 |int                                                                           |null   |\n",
      "|order_status                |string                                                                        |null   |\n",
      "|                            |                                                                              |       |\n",
      "|# Detailed Table Information|                                                                              |       |\n",
      "|Database                    |009490_retail                                                                 |       |\n",
      "|Table                       |orders                                                                        |       |\n",
      "|Owner                       |itv009490                                                                     |       |\n",
      "|Created Time                |Sat Oct 28 15:30:18 EDT 2023                                                  |       |\n",
      "|Last Access                 |UNKNOWN                                                                       |       |\n",
      "|Created By                  |Spark 3.1.2                                                                   |       |\n",
      "|Type                        |MANAGED                                                                       |       |\n",
      "|Provider                    |hive                                                                          |       |\n",
      "|Table Properties            |[transient_lastDdlTime=1698521421]                                            |       |\n",
      "|Statistics                  |2999944 bytes                                                                 |       |\n",
      "|Location                    |hdfs://m01.itversity.com:9000/user/itv009490/warehouse/009490_retail.db/orders|       |\n",
      "|Serde Library               |org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                            |       |\n",
      "|InputFormat                 |org.apache.hadoop.mapred.TextInputFormat                                      |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat                    |       |\n",
      "+----------------------------+------------------------------------------------------------------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"desc extended  009490_retail.orders\").show(truncate=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "210de86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"drop table 009490_retail.orders \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af3922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418f20de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9840e4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE table if not exists 009490_retail.orders_ext (order_id INT, order_date STRING, customer_id INT, order_status STRING)\n",
    "using csv location '/public/trendytech/retail_db/orders'\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8bc0dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+----------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                       |comment|\n",
      "+----------------------------+----------------------------------------------------------------+-------+\n",
      "|order_id                    |int                                                             |null   |\n",
      "|order_date                  |string                                                          |null   |\n",
      "|customer_id                 |int                                                             |null   |\n",
      "|order_status                |string                                                          |null   |\n",
      "|                            |                                                                |       |\n",
      "|# Detailed Table Information|                                                                |       |\n",
      "|Database                    |009490_retail                                                   |       |\n",
      "|Table                       |orders_ext                                                      |       |\n",
      "|Owner                       |itv009490                                                       |       |\n",
      "|Created Time                |Sat Oct 28 16:09:22 EDT 2023                                    |       |\n",
      "|Last Access                 |UNKNOWN                                                         |       |\n",
      "|Created By                  |Spark 3.1.2                                                     |       |\n",
      "|Type                        |EXTERNAL                                                        |       |\n",
      "|Provider                    |csv                                                             |       |\n",
      "|Location                    |hdfs://m01.itversity.com:9000/public/trendytech/retail_db/orders|       |\n",
      "|Serde Library               |org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe              |       |\n",
      "|InputFormat                 |org.apache.hadoop.mapred.SequenceFileInputFormat                |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat       |       |\n",
      "+----------------------------+----------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"desc formatted 009490_retail.orders_ext\"\"\").show(truncate=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cba24f27",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Operation not allowed: TRUNCATE TABLE on external tables: `009490_retail`.`orders_ext`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-068e18a9ce3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\"truncate table 009490_retail.orders_ext\"\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \"\"\"\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtableName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-3.1.2-bin-hadoop3.2/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-3.1.2-bin-hadoop3.2/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Operation not allowed: TRUNCATE TABLE on external tables: `009490_retail`.`orders_ext`"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"truncate table 009490_retail.orders_ext\"\"\").show(truncate=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710d80d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
